"""
Markdown report generator with structured privacy policy analysis.
Supports comprehensive reporting with evidence tracking.
"""
import json
from typing import Dict, List, Optional
from datetime import datetime
from pathlib import Path


class MarkdownReporter:
    """
    Generate structured Markdown reports for privacy policy analysis.
    Default output format, with optional PDF conversion.
    """
    
    def __init__(self, template_path: str = None):
        """
        Args:
            template_path: Path to prompt template JSON (optional)
        """
        self.template_path = template_path
        self.dimensions = self._load_dimensions()
    
    def _load_dimensions(self) -> List[Dict]:
        """Load analysis dimensions from template"""
        if self.template_path and Path(self.template_path).exists():
            with open(self.template_path, 'r', encoding='utf-8') as f:
                template = json.load(f)
                return template.get('analysis_dimensions', [])
        return []
    
    def generate_report(
        self,
        url: str,
        company_name: str,
        analysis_results: List[Dict],
        metadata: Optional[Dict] = None
    ) -> str:
        """
        Generate comprehensive Markdown report.
        
        Args:
            url: Privacy policy URL
            company_name: Company name
            analysis_results: List of analysis results (question + response)
            metadata: Optional metadata (chunk count, processing time, etc.)
            
        Returns:
            Markdown formatted report
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Build report sections
        sections = []
        
        # Header
        sections.append(self._generate_header(company_name, url, timestamp, metadata))
        
        # Executive Summary
        sections.append(self._generate_executive_summary(analysis_results))
        
        # Detailed Analysis by Dimension
        sections.append(self._generate_dimensional_analysis(analysis_results))
        
        # Evidence Table
        sections.append(self._generate_evidence_table(analysis_results))
        
        # Coverage Assessment
        sections.append(self._generate_coverage_assessment(analysis_results))
        
        # Appendix
        sections.append(self._generate_appendix(metadata))
        
        return '\n\n'.join(sections)
    
    def _generate_header(
        self,
        company_name: str,
        url: str,
        timestamp: str,
        metadata: Optional[Dict]
    ) -> str:
        """Generate report header"""
        header = f"""# Privacy Policy Analysis Report

**Company:** {company_name}  
**Policy URL:** [{url}]({url})  
**Analysis Date:** {timestamp}  
**Generated by:** PrivacyPilot v2.0 (Hybrid RAG Pipeline)
"""
        
        if metadata:
            header += f"\n**Document Chunks:** {metadata.get('chunk_count', 'N/A')}  "
            header += f"\n**Processing Time:** {metadata.get('processing_time', 'N/A')}s  "
            header += f"\n**Embedding Model:** {metadata.get('embedding_model', 'N/A')}"
        
        header += "\n\n---"
        return header
    
    def _generate_executive_summary(self, results: List[Dict]) -> str:
        """Generate executive summary section"""
        summary = "## Executive Summary\n\n"
        
        # Calculate overall scores
        total = len(results)
        high_conf = sum(1 for r in results if r.get('response', {}).get('confidence') == 'high')
        complete = sum(1 for r in results if r.get('response', {}).get('coverage') == 'complete')
        
        summary += f"This report analyzes **{total} key privacy dimensions** of the policy.\n\n"
        summary += f"**Overall Assessment:**\n"
        summary += f"- High Confidence Answers: {high_conf}/{total} ({high_conf/total*100:.0f}%)\n"
        summary += f"- Complete Coverage: {complete}/{total} ({complete/total*100:.0f}%)\n\n"
        
        # Key findings
        summary += "**Key Findings:**\n"
        
        for result in results[:5]:  # Top 5 most important findings
            resp = result.get('response', {})
            if resp.get('confidence') == 'high' and resp.get('coverage') in ['complete', 'partial']:
                question = result.get('question', '')
                answer = resp.get('answer', '')
                summary += f"- **{question}**  \n  {answer[:150]}{'...' if len(answer) > 150 else ''}\n"
        
        return summary
    
    def _generate_dimensional_analysis(self, results: List[Dict]) -> str:
        """Generate detailed analysis by dimension"""
        analysis = "## Detailed Analysis\n\n"
        
        # Group results by dimension
        by_dimension = {}
        for result in results:
            dim = result.get('dimension', 'Other')
            if dim not in by_dimension:
                by_dimension[dim] = []
            by_dimension[dim].append(result)
        
        # Generate section for each dimension
        for dimension, dim_results in by_dimension.items():
            analysis += f"### {dimension}\n\n"
            
            for result in dim_results:
                question = result.get('question', '')
                resp = result.get('response', {})
                answer = resp.get('answer', '')
                confidence = resp.get('confidence', 'unknown')
                coverage = resp.get('coverage', 'unknown')
                
                # Question and answer
                analysis += f"**Q: {question}**\n\n"
                analysis += f"**A:** {answer}\n\n"
                
                # Metadata badges
                analysis += f"*Confidence: `{confidence}` | Coverage: `{coverage}`*\n\n"
                
                # Evidence
                evidence = resp.get('evidence', [])
                if evidence:
                    analysis += "**Evidence:**\n"
                    for i, ev in enumerate(evidence, 1):
                        chunk_id = ev.get('chunk_id', 'unknown')
                        quote = ev.get('quote', '')
                        relevance = ev.get('relevance', 'unknown')
                        
                        analysis += f"{i}. [Chunk {chunk_id}] ({relevance} relevance)  \n"
                        analysis += f"   > {quote}\n\n"
                
                analysis += "---\n\n"
        
        return analysis
    
    def _generate_evidence_table(self, results: List[Dict]) -> str:
        """Generate consolidated evidence table"""
        table = "## Evidence Reference Table\n\n"
        table += "| Chunk ID | Question | Quote | Relevance |\n"
        table += "|----------|----------|-------|----------|\n"
        
        for result in results:
            question = result.get('question', '')[:50]  # Truncate
            resp = result.get('response', {})
            
            for ev in resp.get('evidence', []):
                chunk_id = ev.get('chunk_id', '')
                quote = ev.get('quote', '')[:100]  # Truncate
                relevance = ev.get('relevance', '')
                
                # Escape pipes in text
                quote_escaped = quote.replace('|', '\\|')
                question_escaped = question.replace('|', '\\|')
                
                table += f"| {chunk_id} | {question_escaped}... | {quote_escaped}... | {relevance} |\n"
        
        return table
    
    def _generate_coverage_assessment(self, results: List[Dict]) -> str:
        """Generate coverage assessment section"""
        assessment = "## Coverage Assessment\n\n"
        
        # Count by coverage type
        coverage_counts = {'complete': 0, 'partial': 0, 'none': 0}
        for result in results:
            coverage = result.get('response', {}).get('coverage', 'none')
            coverage_counts[coverage] = coverage_counts.get(coverage, 0) + 1
        
        total = len(results)
        
        assessment += "This section assesses how well the privacy policy addresses each question:\n\n"
        assessment += f"- **Complete Coverage:** {coverage_counts['complete']}/{total} ({coverage_counts['complete']/total*100:.0f}%)  \n"
        assessment += f"  Policy explicitly addresses the question with clear information.\n\n"
        assessment += f"- **Partial Coverage:** {coverage_counts['partial']}/{total} ({coverage_counts['partial']/total*100:.0f}%)  \n"
        assessment += f"  Policy mentions the topic but lacks detail or clarity.\n\n"
        assessment += f"- **No Coverage:** {coverage_counts['none']}/{total} ({coverage_counts['none']/total*100:.0f}%)  \n"
        assessment += f"  Policy does not address the question.\n\n"
        
        # List gaps
        gaps = [r.get('question', '') for r in results if r.get('response', {}).get('coverage') == 'none']
        if gaps:
            assessment += "**Policy Gaps:**\n"
            for gap in gaps:
                assessment += f"- {gap}\n"
        
        return assessment
    
    def _generate_appendix(self, metadata: Optional[Dict]) -> str:
        """Generate appendix with technical details"""
        appendix = "## Appendix\n\n"
        appendix += "### Technical Details\n\n"
        
        if metadata:
            appendix += "**Retrieval Configuration:**\n"
            appendix += f"- Chunking: {metadata.get('chunk_size', 512)} tokens, {metadata.get('overlap', 100)} overlap\n"
            appendix += f"- Embedding Model: {metadata.get('embedding_model', 'N/A')}\n"
            appendix += f"- Retrieval: Hybrid (BM25 + Dense Vectors)\n"
            appendix += f"- Top-K Retrieved: {metadata.get('top_k', 10)}\n\n"
        
        appendix += "**Analysis Method:**\n"
        appendix += "- Framework: Hybrid RAG (Retrieval-Augmented Generation)\n"
        appendix += "- LLM: Groq (llama-3.3-70b-versatile)\n"
        appendix += "- Evidence Tracking: Chunk-level citations\n"
        appendix += "- Output Format: Structured JSON with confidence scores\n\n"
        
        appendix += "---\n\n"
        appendix += "*Report generated by PrivacyPilot - Advanced Privacy Policy Analysis Tool*"
        
        return appendix
    
    def save_report(self, report: str, output_path: str):
        """
        Save report to file.
        
        Args:
            report: Markdown report content
            output_path: Output file path (.md)
        """
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"Report saved to: {output_path}")
    
    def convert_to_pdf(self, markdown_path: str, pdf_path: str = None):
        """
        Convert Markdown report to PDF (optional).
        Requires: pip install markdown-pdf or weasyprint
        
        Args:
            markdown_path: Input .md file
            pdf_path: Output .pdf file (optional, auto-generated if None)
        """
        try:
            from weasyprint import HTML, CSS
            from markdown import markdown
            
            if pdf_path is None:
                pdf_path = str(Path(markdown_path).with_suffix('.pdf'))
            
            # Read markdown
            with open(markdown_path, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # Convert to HTML
            html_content = markdown(md_content, extensions=['tables', 'fenced_code'])
            
            # Add basic CSS
            css = CSS(string='''
                body { font-family: Arial, sans-serif; line-height: 1.6; padding: 20px; }
                h1 { color: #2c3e50; border-bottom: 2px solid #3498db; }
                h2 { color: #34495e; margin-top: 30px; }
                h3 { color: #7f8c8d; }
                code { background-color: #f4f4f4; padding: 2px 6px; }
                blockquote { border-left: 4px solid #3498db; padding-left: 15px; color: #555; }
                table { border-collapse: collapse; width: 100%; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
                th { background-color: #3498db; color: white; }
            ''')
            
            # Generate PDF
            HTML(string=html_content).write_pdf(pdf_path, stylesheets=[css])
            print(f"PDF saved to: {pdf_path}")
            
        except ImportError:
            print("PDF conversion requires: pip install weasyprint markdown")
            print("Skipping PDF generation. Markdown report available at:", markdown_path)


# Convenience function
def generate_privacy_report(
    url: str,
    company_name: str,
    analysis_results: List[Dict],
    output_dir: str = "reports",
    save_pdf: bool = False,
    metadata: Optional[Dict] = None
) -> str:
    """
    Quick function to generate and save privacy policy report.
    
    Args:
        url: Privacy policy URL
        company_name: Company name
        analysis_results: List of Q&A results
        output_dir: Output directory for reports
        save_pdf: Whether to generate PDF
        metadata: Optional metadata
        
    Returns:
        Path to saved Markdown report
    """
    reporter = MarkdownReporter()
    
    # Generate report
    report = reporter.generate_report(url, company_name, analysis_results, metadata)
    
    # Create output path
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_name = company_name.replace(' ', '_').replace('/', '_')
    md_path = Path(output_dir) / f"{safe_name}_analysis_{timestamp}.md"
    
    # Save Markdown
    reporter.save_report(report, str(md_path))
    
    # Optionally convert to PDF
    if save_pdf:
        reporter.convert_to_pdf(str(md_path))
    
    return str(md_path)
